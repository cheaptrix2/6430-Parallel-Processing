{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85665ccd-3de9-461f-b7ac-3a60392a6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import to find Spark on PC\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "# Importing pyspark and Spark Session\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Importing time module\n",
    "import os, psutil\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "# Importing .csv module to write to file\n",
    "import csv\n",
    "from csv import writer\n",
    "# Lists for variable to be written to the data files\n",
    "time_list = []\n",
    "memory_list = []\n",
    "features_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61223851-29dc-436a-9a63-f6caade1cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    # Getting the process id\n",
    "    process = psutil.Process(os.getpid())\n",
    "    \n",
    "    # Creating a pyspark instance\n",
    "    spark = SparkSession.builder.master(\"local[1]\").appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "    # Start time variable\n",
    "    time_start = datetime.now()\n",
    "\n",
    "    ########### Starting transformation code ###########\n",
    "    # Loading data file into dataframe\n",
    "    df = spark.read.csv(\"ecg.csv\", header=False, inferSchema=True)\n",
    "    # Additional data set (~12 GB)\n",
    "    #df = spark.read.csv(\"dataset_aug_500_full.csv/dataset_aug_500_full.csv\", header=False, inferSchema=True)\n",
    "    # Converting dataframe to rdd so we can use map()\n",
    "    rdd = df.rdd\n",
    "    # Use map() function to transform\n",
    "    rdd2 = rdd.map(lambda x: (x[0:-2], float(x[-1])))\n",
    "    ########### End transformation code ###########\n",
    "\n",
    "    # Calculate time\n",
    "    end_time = datetime.now() - time_start\n",
    "    #print(\"Time of the program was:\", end_time.total_seconds(), \"seconds.\")\n",
    "    # Calculate memory of the process used\n",
    "    memory_used = process.memory_info().rss / 1000000\n",
    "    #print(\"Data used in MB:\", memory_used, \"MB\")\n",
    "\n",
    "    ########### Writing to data files ###########\n",
    "    # Opening/creating Time and Memoery data files\n",
    "    time_file = open('Masters_Project_Time.csv', 'a')\n",
    "    memory_file = open('Masters_Project_Memory.csv', 'a')\n",
    "\n",
    "    # Creating csv readers\n",
    "    time_reader = csv.reader(time_file)\n",
    "    memory_reader = csv.reader(memory_file)\n",
    "    #next_time_row = time_reader.next()\n",
    "\n",
    "    # Creating .csv writer object for time_file and memory_file\n",
    "    time_writer_obj = writer(time_file)\n",
    "    memory_writer_obj = writer(memory_file)\n",
    "\n",
    "    # Adding data to the list for insertion to .csv file\n",
    "    time_list.append(end_time.total_seconds())\n",
    "    memory_list.append(memory_used)\n",
    "\n",
    "    # Sending lists objects to the object writer\n",
    "    #time_reader.append(time_list)\n",
    "\n",
    "    time_writer_obj.writerow(time_list)\n",
    "    memory_writer_obj.writerow(memory_list)\n",
    "\n",
    "    # Closing files\n",
    "    time_file.close()\n",
    "    memory_file.close()\n",
    "\n",
    "    #Resetting list for new run\n",
    "    time_list = []\n",
    "    memory_list = []\n",
    "    \n",
    "    spark.stop\n",
    "\n",
    "# Closing the files\n",
    "time_file.close()\n",
    "memory_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583f84af-7a67-4c4f-afcd-ffd173e9fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df22 = rdd.toDF()\n",
    "#df22.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14224ba-e9e5-44be-a197-eeeaed19a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to add values to the columns and print\n",
    "# Not neccessary for research\n",
    "# Will not be counted for time or process\n",
    "#df3 = rdd2.toDF()\n",
    "#df3 = df3.withColumnRenamed(\"_1\",\"Values\")\n",
    "#df3 = df3.withColumnRenamed(\"_2\",\"Designation\")\n",
    "#print(df3.show(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad391a22-f29c-475d-aa72-1c08af071d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((f\"{rdd.count():,}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fde9ff9-38e5-4ef9-9785-e05a8d974454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print((f\"{4998 * 141:,}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f47c494-2a86-48c8-bc07-0e0411508f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### TEST CODE #########################\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, DoubleType, FloatType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "for field in df.schema.fields:\n",
    "    features_list.append(field.name)\n",
    "\n",
    "assembler = VectorAssembler(inputCols = features_list, outputCol='features')\n",
    "dfTest = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62343162-40f7-4cd4-beb0-fc1270e8de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfTest = dfTest.select('features','_c140')\n",
    "dfTest = dfTest.select('_c140','features')\n",
    "dfTest = dfTest.withColumnRenamed(\"_c140\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bbc165-2e40-4b9e-b181-7d074e874bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|[-0.11252183,-2.8...|\n",
      "|    1|[-1.1008778,-3.99...|\n",
      "|    1|[-0.56708802,-2.5...|\n",
      "|    1|[0.49047253,-1.91...|\n",
      "|    1|[0.80023202,-0.87...|\n",
      "|    1|[-1.5076736,-3.57...|\n",
      "|    1|[-0.297161,-2.766...|\n",
      "|    1|[0.44676853,-1.50...|\n",
      "|    1|[0.087630577,-1.7...|\n",
      "|    1|[-0.83228111,-1.7...|\n",
      "|    1|[0.084430128,-3.1...|\n",
      "|    1|[-0.007819138,-2....|\n",
      "|    1|[-1.0743015,-3.25...|\n",
      "|    1|[4.0581274,2.0878...|\n",
      "|    1|[-0.76160326,-2.9...|\n",
      "|    1|[-0.18649962,-2.6...|\n",
      "|    1|[0.80393944,-1.10...|\n",
      "|    1|[-0.92021269,-2.4...|\n",
      "|    1|[2.7446026,-0.101...|\n",
      "|    1|[2.4028692,2.0367...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfTest.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fceb35-d2f6-4de7-bacb-27d74172dc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.000889\n",
      "r2: 0.999997\n"
     ]
    }
   ],
   "source": [
    "trainDF,testDF=dfTest.randomSplit([0.75,0.25],seed=1)\n",
    "#Fit with linear regression model:\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "model = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "model=model.fit(trainDF)\n",
    "trainingSummary = model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c0bd50-410e-4b9f-be8a-354dc35a3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|          prediction|label|            features|\n",
      "+--------------------+-----+--------------------+\n",
      "|-0.00259846069431...|    0|[-4.3750582,-5.50...|\n",
      "|1.735302921425459E-4|    0|[-2.878857,-3.339...|\n",
      "|8.759735315672149E-4|    0|[-2.8769322,-3.65...|\n",
      "|0.002250124153678...|    0|[-2.8596916,-2.87...|\n",
      "|-2.24689530915150...|    0|[-2.7627317,-3.55...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=model.transform(testDF)\n",
    "pred.select(\"prediction\",\"label\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ba4a082-6e30-46ea-9909-701d2c747f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test:  0.9999954100328904\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"label\",metricName=\"r2\")\n",
    "print(\"R2 on test: \", evaluator.evaluate(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673670a-88ad-4f94-af31-91411e80e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE - CORRECTING FOR UNDER SAMPLING\n",
    "#MAKE SURE THERE IS EVEN DISTROBUTION IN CLASSIFICATIONS (1/0)\n",
    "\n",
    "#MAKE SURE SPARK INSTALLATION USES GPU\n",
    "\n",
    "#LOOK UP CLASSIFICATION MODELS\n",
    "#DECISION TREE, RANDOM FORREST, K-MEANS (HYPERPARRAMATER TUNING), NURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5833b0de-0464-4a0e-bde2-a6c4789633dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: (141,[3,132,133,134,135,136,140],[-0.012737507243149178,0.014415660657596847,0.015261412908894597,0.013788004919105316,0.008322931590231902,0.004989129347868306,1.7054845093269158])\n",
      "Intercept: -0.6344093786656071\n",
      "Multinomial coefficients: 2 X 141 CSRMatrix\n",
      "(0,3) 0.007\n",
      "(0,4) 0.0023\n",
      "(0,116) 0.0005\n",
      "(0,117) 0.003\n",
      "(0,132) -0.0118\n",
      "(0,133) -0.0124\n",
      "(0,134) -0.0112\n",
      "(0,135) -0.0048\n",
      "(0,136) -0.0032\n",
      "(0,140) -0.972\n",
      "(1,3) -0.007\n",
      "(1,4) -0.0023\n",
      "(1,116) -0.0005\n",
      "(1,117) -0.003\n",
      "(1,132) 0.0118\n",
      "(1,133) 0.0124\n",
      "..\n",
      "..\n",
      "Multinomial intercepts: [0.38459356725755256,-0.38459356725755256]\n"
     ]
    }
   ],
   "source": [
    "############################### USING DATASET ###############################\n",
    "######################## BINOMIAL LOGISTIC REGRESSION #######################\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "#training = spark.read.format(\"libsvm\").load(\"sample_libsvm_data.txt\")\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(dfTest)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(dfTest)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0a24d4-fc27-4999-af6a-dea600b6e511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.6789566322072351\n",
      "0.6682085519973944\n",
      "0.6304624784271434\n",
      "0.62607547311837\n",
      "0.6112940244363847\n",
      "0.600482248875369\n",
      "0.5948687711137275\n",
      "0.5858237059885798\n",
      "0.5793809899404818\n",
      "0.5767230001273653\n",
      "0.574016632577398\n",
      "+---+--------------------+\n",
      "|FPR|                 TPR|\n",
      "+---+--------------------+\n",
      "|0.0|                 0.0|\n",
      "|0.0|0.001370332305584...|\n",
      "|0.0|0.002740664611168...|\n",
      "|0.0|0.004110996916752...|\n",
      "|0.0|0.005481329222336417|\n",
      "|0.0|0.006851661527920521|\n",
      "|0.0|0.008221993833504625|\n",
      "|0.0|0.009592326139088728|\n",
      "|0.0|0.010962658444672833|\n",
      "|0.0|0.012332990750256937|\n",
      "|0.0|0.013703323055841042|\n",
      "|0.0|0.015073655361425145|\n",
      "|0.0| 0.01644398766700925|\n",
      "|0.0|0.017814319972593355|\n",
      "|0.0|0.019184652278177457|\n",
      "|0.0|0.020554984583761562|\n",
      "|0.0|0.021925316889345667|\n",
      "|0.0|0.023295649194929772|\n",
      "|0.0|0.024665981500513873|\n",
      "|0.0| 0.02603631380609798|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "areaUnderROC: 0.9999997528260632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression_bbc1c646324b"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################### USING DATASET ###############################\n",
    "######################## BINOMIAL LOGISTIC REGRESSION #######################\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Extract the summary from the returned LogisticRegressionModel instance trained\n",
    "# in the earlier example\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# Obtain the receiver-operating characteristic as a dataframe and areaUnderROC.\n",
    "trainingSummary.roc.show()\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# Set the model threshold to maximize F-Measure\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head()\n",
    "bestThreshold = fMeasure.where(fMeasure['F-Measure'] == maxFMeasure['max(F-Measure)']) \\\n",
    "    .select('threshold').head()['threshold']\n",
    "lr.setThreshold(bestThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "040ede7a-286a-477d-8a91-7c273b690273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      "1 X 141 CSRMatrix\n",
      "(0,3) -0.0127\n",
      "(0,132) 0.0144\n",
      "(0,133) 0.0153\n",
      "(0,134) 0.0138\n",
      "(0,135) 0.0083\n",
      "(0,136) 0.005\n",
      "(0,140) 1.7055\n",
      "Intercept: [-0.6344093786656071]\n",
      "objectiveHistory:\n",
      "0.6789566322072351\n",
      "0.6682085519973944\n",
      "0.6304624784271434\n",
      "0.62607547311837\n",
      "0.6112940244363847\n",
      "0.600482248875369\n",
      "0.5948687711137275\n",
      "0.5858237059885798\n",
      "0.5793809899404818\n",
      "0.5767230001273653\n",
      "0.574016632577398\n",
      "False positive rate by label:\n",
      "label 0: 0.0\n",
      "label 1: 0.0\n",
      "True positive rate by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "Precision by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "Recall by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "F-measure by label:\n",
      "label 0: 1.0\n",
      "label 1: 1.0\n",
      "Accuracy: 1.0\n",
      "FPR: 0.0\n",
      "TPR: 1.0\n",
      "F-measure: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "############################### USING DATASET ###############################\n",
    "######################## MULTINOMIAL LOGISTIC REGRESSION #######################\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "#training = spark \\\n",
    "#    .read \\\n",
    "#    .format(\"libsvm\") \\\n",
    "#    .load(\"data/mllib/sample_multiclass_classification_data.txt\")\n",
    "\n",
    "lr2 = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel2 = lr2.fit(dfTest)\n",
    "\n",
    "# Print the coefficients and intercept for multinomial logistic regression\n",
    "print(\"Coefficients: \\n\" + str(lrModel2.coefficientMatrix))\n",
    "print(\"Intercept: \" + str(lrModel2.interceptVector))\n",
    "\n",
    "trainingSummary = lrModel2.summary\n",
    "\n",
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)\n",
    "\n",
    "# for multiclass, we can inspect metrics on a per-label basis\n",
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))\n",
    "\n",
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))\n",
    "\n",
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))\n",
    "\n",
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))\n",
    "\n",
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fc13d46-e0c2-46bc-ad88-8a6425604096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0|[-4.4863068,-5.44...|\n",
      "|       1.0|         1.0|[-4.3750582,-5.50...|\n",
      "|       1.0|         1.0|[-3.3947195,-2.36...|\n",
      "|       1.0|         1.0|[-2.878857,-3.339...|\n",
      "|       1.0|         1.0|[-2.7604703,-3.28...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0 \n",
      "Accuracy: 1.0\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_5b06329b2be8, depth=1, numNodes=3, numClasses=2, numFeatures=141\n"
     ]
    }
   ],
   "source": [
    "############################### USING DATASET ###############################\n",
    "########################## DECISION TREE CLASSIFIER #########################\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load the data stored in LIBSVM format as a DataFrame.\n",
    "#data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(dfTest)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(dfTest)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = dfTest.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc1d2f32-46bf-4078-9a8d-25497faa4f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|             0|    0|[-5.1480379,-5.80...|\n",
      "|             0|    0|[-3.4477298,-3.74...|\n",
      "|             0|    0|[-3.3947195,-2.36...|\n",
      "|             0|    0|[-3.0182078,-2.99...|\n",
      "|             0|    0|[-2.878857,-3.339...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.00877785\n",
      "Accuracy: 0.9912221471978393\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_eb75e76f873e, numTrees=10, numClasses=2, numFeatures=141\n"
     ]
    }
   ],
   "source": [
    "############################### USING DATASET ###############################\n",
    "########################## RANDOM FOREST CLASSIFIER #########################\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "#data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(dfTest)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(dfTest)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = dfTest.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b333efc9-6e66-4123-a729-a7c3d42377ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0|[-4.7147993,-4.50...|\n",
      "|       1.0|         1.0|[-4.4863068,-5.44...|\n",
      "|       1.0|         1.0|[-3.3947195,-2.36...|\n",
      "|       1.0|         1.0|[-3.3918306,-3.53...|\n",
      "|       1.0|         1.0|[-3.0182078,-2.99...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0\n",
      "Accuracy: 1.0\n",
      "GBTClassificationModel: uid = GBTClassifier_ddb9ffa4db79, numTrees=10, numClasses=2, numFeatures=141\n"
     ]
    }
   ],
   "source": [
    "############################### USING DATASET ###############################\n",
    "###################### GRADIENT-BOOSTED TREE CLASSIFIER #####################\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "#data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(dfTest)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(dfTest)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = dfTest.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "gbtModel = model.stages[2]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "880a7acd-112a-44f8-8aec-f89ab803d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINCIPLE COMPONENT ANALASIS. (PCA)\n",
    "\n",
    "from pyspark.mllib.feature import PCA as PCAmllib\n",
    "from pyspark.ml.feature import PCA as PCAml\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "#rddTest = dfTest.rdd\n",
    "#model = PCAmllib(2).fit(rddTest)\n",
    "#transformed = model.transform(rddTest)\n",
    "\n",
    "pca = PCAml(k=2, inputCol=\"features\", outputCol=\"pca\")\n",
    "model = pca.fit(dfTest)\n",
    "transformed = model.transform(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881e5544-e3aa-48c8-8314-12a4791bfd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            features|                 pca|\n",
      "+-----+--------------------+--------------------+\n",
      "|    1|[-0.11252183,-2.8...|[5.96480266558478...|\n",
      "|    1|[-1.1008778,-3.99...|[5.99255966425208...|\n",
      "|    1|[-0.56708802,-2.5...|[5.29932423996655...|\n",
      "|    1|[0.49047253,-1.91...|[6.48089918483401...|\n",
      "|    1|[0.80023202,-0.87...|[7.46758441196614...|\n",
      "|    1|[-1.5076736,-3.57...|[7.6297788551766,...|\n",
      "|    1|[-0.297161,-2.766...|[6.91009144926080...|\n",
      "|    1|[0.44676853,-1.50...|[7.26779864417878...|\n",
      "|    1|[0.087630577,-1.7...|[6.95843468514935...|\n",
      "|    1|[-0.83228111,-1.7...|[8.56387498185476...|\n",
      "|    1|[0.084430128,-3.1...|[7.63369989307515...|\n",
      "|    1|[-0.007819138,-2....|[8.15855206910915...|\n",
      "|    1|[-1.0743015,-3.25...|[6.82984947353546...|\n",
      "|    1|[4.0581274,2.0878...|[2.39496239344078...|\n",
      "|    1|[-0.76160326,-2.9...|[7.19614953841633...|\n",
      "|    1|[-0.18649962,-2.6...|[7.63097653909742...|\n",
      "|    1|[0.80393944,-1.10...|[6.13455146397497...|\n",
      "|    1|[-0.92021269,-2.4...|[3.39696539588544...|\n",
      "|    1|[2.7446026,-0.101...|[6.47399316527980...|\n",
      "|    1|[2.4028692,2.0367...|[6.39079090038333...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5db357-39a2-43d8-b7c6-8efe8ae93bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNPACKING PCA DATA?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
